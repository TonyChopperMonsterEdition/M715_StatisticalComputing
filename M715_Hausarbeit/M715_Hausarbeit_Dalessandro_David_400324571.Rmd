---
title: "Crimes and their relation to socio-economic factors"
subtitle: "Linear Regression based on the federal states <br> Modul 715 - Statistical Computing"
author: 
  name: "D'Alessandro David"
  url: "https://github.com/TonyChopperMonsterEdition/M715_StatisticalComputing/tree/2536b0a7dfc4fa8ccc7150315d5f05941734e835/M715_Hausarbeit"
date: "`r Sys.Date()`"
output:  
  #html_document:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 2
    highlight: default 
    theme: paper
    css: "./09_Formatierung/stylesheetCaseStudy.css"
    number_paragraphs: yes
    code_folding:  show #hide
    fig_caption: False
bibliography: "./10_Literatur_Quellen/m715_references.bib"
csl: "https://www.zotero.org/styles/apa"
lang: en


##Formatierung
geometry: left=2cm,right=4cm,top=2cm,bottom=2cm

knit: (function(inputFile, encoding) {
      out_dir <- "08_Report";
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), out_dir, 'M715_Hausarbeit_Dalessandro_David_400324571.html')) })
                        
---



```{r setup, include=FALSE}
# load libraries from before
#### zuvor geladen:
#library(rmarkdown)
library(knitr)
library(bookdown)
#library(yaml)

# globaloptions
knitr::opts_chunk$set(echo = FALSE)
# Tabellnaming and Counting activated --> Table X 
options(table_counter = TRUE, table_counter_str = "Table %s:", scipen = 15 )

```

# Preface {.unnumbered}
This paper was created with Rmarkdown. All the data that was used to build this paper is also available on [Github](https://github.com/TonyChopperMonsterEdition/M715_StatisticalComputing/tree/2536b0a7dfc4fa8ccc7150315d5f05941734e835/M715_Hausarbeit). This includes the Data from the Federal Criminal Police Office and the Federal Statistical Office from Germany, the Rmarkdown-File or any artifact that was built or used by the RMarkdown-File. You are free to use any of the data inside and make your own calculations.Especially, the data from the German offices is [licensed](https://www.govdata.de/dl-de/by-2-0) for an open commercial and non-commericial use. Additionally, you will find a German and an English version of this Rmarkdown in the Repository, the English version does not have any extensions in its filename. In the **08_Report** folder, you find two HTML Files, which results from the Rmarkdown.
<ul>
<li> M715_Hausarbeit_Dalessandro_David_400324571.html – English version </li>
<li> M715_Hausarbeit_Dalessandro_David_400324571_de.html – German version </li>
</ul>
You can create these HTML files by yourself, if you
<ol class="vorwort_ol"> 
<li> pull the git repository, </li>
<li> keep the structure, </li>
<li> knit one of the rmd-File in the M715_Hausarbeit(Root)-Directory. </li>
</ol>
If rendering is not working, check [Appendix 1][Appendix 1]. Information about the runtime environment, which created this document, are provided there. If you need assistance to render the document or have any further questions, do not hesitate to leave me a message on my studynet-account. Furthermore the **08_Report**-Folder contains the **statutory declaration**, which confirms that I have created this paper on my own and without further help. Ultimately, I trust that you will find the Case Study to be of interest and I would be pleased to receive your feedback regarding any further enhancements.

***
# Introduction {#Chapter1}
According to crime statistics from the Federal Criminal Police Office, two billion euros damage was caused by around two million thefts in 2022. With over 400,000 cases, North Rhine-Westphalia had documented the most.^[cf. @Bundeskriminalamt.2022] There are many ways to prevent thefts and to protect the population. So, it makes take a look at the influences on the commission of crimes. In the case of this paper, the federal states and their different socio-economic factors will be focused. For this reason, factors like the cultural and educational expenditure, the number of inhabitants, the gross domestic product and the number of social welfare recipients are the subject of the investigation.

This paper asks if the amount of theft is related to some above-mentioned socio-economic factors. The null hypothesis is that they do not have any relation to it. But the assumption is that higher cultural or educational expenditures provide better social integration, create alternative leisure activities or career opportunities for potentially vulnerable people, and thus reduce the number of thefts. On the other side, the gross domestic product partly represents the economic development and purchasing power of the inhabitants, so the paper expects that the economic success of a federal state is negatively related to the number of cases. This is opposed by the number and density of inhabitants, they could lead directly or as a mediator to an increase in the number of cases if the trend is increasing. The same applies to the number of unemployed people, as their living situation could push them to commit crimes. So, the alternative hypothesis is, that some of these factors, like the amount of unemployed people, increases, while the other factors, like expenditure on culture, will decrease the number of thefts. However, the focus of this paper starts not with the causal link but firstly with the interest in any kind of relation between these factors.
 
Therefore, the study addresses these interest with a linear regression. This decision was made because the linear regression takes all the mentioned factors into account and builds a model to calculate the total number of thefts. To create such a model, this paper uses the data of the Federal Criminal Police Office from 2020 to 2014. In addition, it takes the socio-economic data from the Federal Statistical Office from Germany to build a regression function. The Data of this paper is introduced in the first part of [Chapter 2](#Chapter2). The second part gives an overview of the preparation of the data and how three different models are created to detect relations between the number of thefts and the socio-economic factors. [Chapter 3](#Chapter3) interprets the results and selects the appropriate model. Based on the weaknesses of the work, [Chapter 4](#Chapter4) evaluates the methods and data used and subjects the outcome to a critical review. The paper is rounded off by the conclusion in [Chapter 5](#Chapter5), which summarizes the results and draws implications for further research.

***
#	Methodology {#Chapter2}
This chapter describes and explains the data from the Federal Criminal Police Office ([par. 2.1](#Paragraph2_1)) and the Federal Statistical Office ([par. 2.2](#Paragraph2_2)). The consideration primarily highlights the relevant variables in this work. On the other hand, the chapter shows which processing efforts ([par. 2.3](#Paragraph2_3)) are necessary to model the case numbers ([par. 2.4](#Paragraph2_4)). In support, the thesis uses the following libraries.

```{r Libraries, echo=TRUE, message=FALSE, warning=FALSE}
# Libraries needed for the data exploration 
library(tidyverse)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(grid)
library(ggrepel)
library(purrr)
library(base)
library(data.table)
library(devtools)
library(htmlTable)
```

##	Data of Federal Criminal Police Office {#Paragraph2_1}
In this section, the chapter focuses on the data of the Federal Criminal Police Office. It provides insight into the structure of the datasets and explains which measures ([par. 2.3](#Paragraph2_3)) have to be taken to derive a regression model. For the description and analysis, the paper uses the scripts listed in the code chunk. On the one hand, they load the datasets of the Federal Criminal Police Office into the Rmarkdown environment, and on the other hand, they prepare tables and graphs that the Rmarkdown embeds in this section.

``` {r Datasets & Scripts,echo=TRUE, message=FALSE, warning=FALSE}
# Loading Datasets over the following scripts
source("./00_Skripte/read_PKSdatafiles.r", local = knitr::knit_global())  

# Calculating and creating variables to embed and use them in the paper
## Numbering of Tabels done with option()


# Smaller Thefts in Berlin in 2020 to show the example of the layers and how the figures are calculated
example_Ber <-  caseNumbers_2020[caseNumbers_2020$FederalState %like% "Berlin" & caseNumbers_2020$Crimetype %like% "Diebstahl",]
example_Ber_TheftOnly <- example_Ber[ str_detect(example_Ber$CrimeKey, "^31"),]
cssCell_4_Ber_TheftOnly <- matrix("",ncol=ncol(example_Ber_TheftOnly), nrow=nrow(example_Ber_TheftOnly))
cssCell_4_Ber_TheftOnly[str_detect(example_Ber_TheftOnly$CrimeKey, "^310\\*") | str_detect(example_Ber_TheftOnly$CrimeKey, "^315\\*",)] <- "font.size: 1.1; font-weight: bold"

Table_Ber_TheftOnly <- addHtmlTableStyle(example_Ber_TheftOnly, 
                                   pos.caption = "bottom", 
                                   align="lllr",
                                   align.header = "lccr",
                                   css.cell= cssCell_4_Ber_TheftOnly)
Table_Ber_TheftOnly <- htmlTable(Table_Ber_TheftOnly, 
                                   rnames=FALSE, 
                                   tspanner = "Simple Thefts Layer 2",
                                   n.tspanner = nrow(Table_Ber_TheftOnly),
                                   rgroup = c("Business premises (Layer 3)", "Gastronomy premises (Layer 3)"),
                                   n.rgroup = c(9,nrow(Table_Ber_TheftOnly)-9),
                                   caption="Number of thefts on the 3. Detaildepth in the Federal State of Berlin in 2020^[adapted from @Bundeskriminalamt.2023]",
                                   label="Table_Ber_TheftOnly")

## Example for smaller Thefts
sum_Ber_TheftOnly_total <- prettyNum(sum(example_Ber_TheftOnly[example_Ber_TheftOnly$CrimeKey %like% "\\*", "Casenumbers"]), big.mark = ",",big.interval = 3)
example_Ber_TheftOnly_gastronomic <-  prettyNum(as.numeric(example_Ber_TheftOnly[example_Ber_TheftOnly$CrimeKey %like% "315\\*", "Casenumbers"]), big.mark = ",",big.interval = 3)
example_Ber_TheftOnly_nonGastro <-  prettyNum(as.numeric(example_Ber_TheftOnly[example_Ber_TheftOnly$CrimeKey %like% "310\\*", "Casenumbers"]), big.mark = ",",big.interval = 3)

# Crimes in Berlin in 2020 to show upperlayer for each crimetype and the relevant figures for the paper
example_Ber2_totalCrimeTypes <- caseNumbers_2020[caseNumbers_2020$FederalState %like% "Berlin" & caseNumbers_2020$Crimetype %like% "insgesamt und zwar:",]
Table_Ber2_totalCrimeTypes <- addHtmlTableStyle(example_Ber2_totalCrimeTypes, 
                                   pos.caption = "bottom", 
                                   align="lllr",
                                   align.header = "lccr")
Table_Ber2_totalCrimeTypes <- htmlTable(Table_Ber2_totalCrimeTypes, 
                                   rnames=FALSE, 
                                   tspanner = "Crimecases in total per Crimetype",
                                   n.tspanner = nrow(Table_Ber2_totalCrimeTypes),
                                   caption="Total Numbers per Crimetype in Berlin in 2020^[adapted from @Bundeskriminalamt.2023]",
                                   label="Table_Ber2_totalCrimeTypes")
example_Ber2_Total <- prettyNum(as.numeric(example_Ber2_totalCrimeTypes[,"Casenumbers"]), big.mark = ",",big.interval = 3)

# Create Variable and Table for total number of thefts for all states and years in germany
## Parts of the tables will be displayed in the appendix
thefts_allStates_2014 <-  caseNumbers_2014[ caseNumbers_2014$Crimetype %like% "Diebstahl insgesamt und zwar:",]
thefts_allStates_2015 <-  caseNumbers_2015[ caseNumbers_2015$Crimetype %like% "Diebstahl insgesamt und zwar:",]
thefts_allStates_2017 <-  caseNumbers_2017[ caseNumbers_2017$Crimetype %like% "Diebstahl insgesamt und zwar:",]
thefts_allStates_2018 <-  caseNumbers_2018[ caseNumbers_2018$Crimetype %like% "Diebstahl insgesamt und zwar:",]
thefts_allStates_2020 <-  caseNumbers_2020[ caseNumbers_2020$Crimetype %like% "Diebstahl insgesamt und zwar:",]

## Not clear why, but "Diebstahl insgesamt und zwar" is not working for them that's why additionally CrimeKey is used
thefts_allStates_2016 <-  caseNumbers_2016[ caseNumbers_2016$Crimetype %like% "Diebstahl insgesamt und zwar:" | caseNumbers_2016$CrimeKey %like% "\\*\\*\\*\\*00",]
thefts_allStates_2019 <-  caseNumbers_2019[ caseNumbers_2019$Crimetype %like% "Diebstahl insgesamt und zwar:" | caseNumbers_2019$CrimeKey %like% "\\*\\*\\*\\*00" ,]

table_thefts_allStates2014 <- addHtmlTableStyle(thefts_allStates_2014, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of thefts in each federal state and in germany (2014)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2014")

table_thefts_allStates2020 <- addHtmlTableStyle(thefts_allStates_2020, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of thefts in each federal state and in germany (2020)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2020")

## Variables to show the changes in naming of a variable
example_NationWideUntil2017 <- caseNumbers_2017[caseNumbers_2017$FederalState %like% "Bund echte" & caseNumbers_2017$Crimetype %like% "Diebstahl insgesamt und zwar:",] 
example_NationWideUntil2017 <- arrange(example_NationWideUntil2017,desc(Casenumbers))

example_NationWideSince2018 <- caseNumbers_2018[caseNumbers_2018$FederalState %like% "Bundesrepublik" & caseNumbers_2018$Crimetype %like% "Diebstahl insgesamt und zwar:",] 
example_NationWideSince2018 <- arrange(example_NationWideSince2018,desc(Casenumbers))
```
The Federal Criminal Police Office makes many tables available for download on its website.^[cf. @Bundeskriminalamt.2023] Relevant for this work are the case tables of the federal states in the period from 2014 to 2020 in each case. They contain a scope of `r  toString(totalAmount_CrimeCasesObservations) ` observations. They show the number of offenses, separated by offense and country.^[cf. @Bundeskriminalamt.2021, p. 17] The indicated offense codes allow to differentiate and group the cases. Overall, they detail the offenses on five levels. The tables are supplemented by the interpretation aid, which provides information on the recording of the data or possible distortions. For example, that due to the introduction of a new system in 2019 in Thuringia, not all case numbers were recorded.^[cf. @Bundeskriminalamt.2021b, p.4]

`r Table_Ber_TheftOnly`

[Table. 1](#Table_Ber_TheftOnly) illustrates the importance of levels for petty thefts in Berlin as an example. The total number of smaller thefts `r sum_Ber_TheftOnly_total` results from the case numbers of regular operation (`r example_Ber_TheftOnly_nonGastro`) and catering operation (`r example_Ber_TheftOnly_gastronomic`).^[It should be noted at this point that the work prefers a regular representation of the numbers to visually show the differences between the variables and their magnitude. Textually, the representation is supported by interval points.] The figures shown are from the second level of thefts, below which the third level specifies which case distinctions exist. For example, that motor vehicles were stolen in regular operation. All cases on this level add up to the number of cases on the level above. This means that there is no need to cumulate the case counts, since each level sums up the number of cases from the lower level.

`r Table_Ber2_totalCrimeTypes`

Therefore, the case numbers at the highest level that start with at least one "\*" in the offense code are of interest for this work. [Table 2](#Table_Ber2_totalCrimeTypes) is representative of this and it shows the total number of thefts for Berlin at `r  toString(example_Ber2_Total)`. The table also shows that the highest level of a case type ends with the words *"insgesamt und zwar:"*. Thus, selecting the data via the Crime type column provides an alternative to selecting via the key.

<div class = "row">
  <div class = "column">
  `r table_thefts_allStates2014`
  </div>
  <div class = "column">
  `r table_thefts_allStates2020`
  </div>
</div>

[Table 3](#table_thefts_allStates2017) to [Table 4](#table_thefts_allStates2020) provide an overview of all thefts in the federal states. These values form the target variable that the regression analysis examines. During data preparation, these observations have to be extracted from the remaining ones. The preparation must merge these tables while preserving the year membership of the observation. The observation with Federal State *"Bund echte Zählung der Tatverdächtigen"* or *"Bundesrepublik Deutschland"* is a separate listing of crimes and aggregates all case counts for the states. There is no difference between the designation *"Bund echte Zählung der Tatverdächtigen"* or *"Bundesrepublik Deutschland"* while the former was used until 2017 and the latter from 2018 ([see Appendix 2][Appendix 2]).<br>

It is important to note that it is not the sum of all case counts for the respective states, but that cases that occurred across different states are only recorded once. Thus, this value is unbiased, as it does not record any cases twice. Accordingly, the case numbers of the individual federal states may contain cases that were also documented in other federal states. The following review disproves this fact for thefts by comparing the sum of all case numbers with the total number for the Federal Republic in the respective years.

```{r CheckBias, echo=TRUE, message=TRUE, warning=FALSE}
isBiased <- !(sum(thefts_allStates_2014[1:16,"Casenumbers"]) == thefts_allStates_2014[17,"Casenumbers"] & 
sum(thefts_allStates_2015[1:16,"Casenumbers"]) == thefts_allStates_2015[17,"Casenumbers"] & 
sum(thefts_allStates_2016[1:16,"Casenumbers"]) == thefts_allStates_2016[17,"Casenumbers"] & 
sum(thefts_allStates_2017[1:16,"Casenumbers"]) == thefts_allStates_2017[17,"Casenumbers"] & 
sum(thefts_allStates_2018[1:16,"Casenumbers"]) == thefts_allStates_2018[17,"Casenumbers"] & 
sum(thefts_allStates_2019[1:16,"Casenumbers"]) == thefts_allStates_2019[17,"Casenumbers"] & 
sum(thefts_allStates_2020[1:16,"Casenumbers"]) == thefts_allStates_2020[17,"Casenumbers"] )

isBiased

```

In conclusion, the result `r isBiased` of the check means that the observations of the respective states do not carry case numbers more than once. In this respect, each state represents an unbiased entity in the context of thefts. For [par. 2.3](#Paragraph2_3), the examination of the data resulted in the goal of merging the tables of the respective years and limiting the observations to the case type **"Diebstahl insgesamt und zwar:"**. Another goal is that the year information is preserved when the data is merged. An adjustment of the case type designation or a preservation of the case number are not planned, since the table is to contain only the total number of thefts, the year and federal state from the crime statistics. The data are supplemented by the independent variables, whose origin and meaning are explained in the next section.

***
##	Data of Federal Statistical Office {#Paragraph2_2}

To examine whether the number of thefts in Germany is related to various domestic factors, the paper examines various factors at the state level. For this purpose, it makes use of the Genesis database of the Federal Statistical Office.^[@StatistischesBundesamtDeutschland.2023f] This section focuses on the number of inhabitants^[@StatistischesBundesamtDeutschland.2023], education^[@StatistischesBundesamtDeutschland.2023d] and cultural expenditures^[@StatistischesBundesamtDeutschland.2023c] as well as the unemployment rate^[@StatistischesBundesamtDeutschland.2023b] and economic power^[@StatistischesBundesamtDeutschland.2023e], measured by the gross domestic product generated.

```{r Inhabitants, echo=TRUE, message=FALSE, warning=FALSE}

# Loading Datasets over the following scripts
source("./00_Skripte/read_GENESISdatafiles.r", local = knitr::knit_global())

## Inhabitants
table_population_per_FederalState <- addHtmlTableStyle(head(population_per_FederalState,10), pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Population per federal state per year^[adapted from @StatistischesBundesamtDeutschland.2023]", label="table_population_per_FederalState")

table_population_per_FederalState_headerAdjusted <- addHtmlTableStyle(head(population_per_FederalState_headerAdjusted,10), pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Population per federal state per Year with adjusted headers^[adapted from @StatistischesBundesamtDeutschland.2023]", label="table_population_per_FederalState_headerAdjusted")

```
### Inhabitants {.tabset .tabset-fade}
#### Population per State at the End of a year {-}
`r table_population_per_FederalState `
#### Population, based on the year before {-}
`r table_population_per_FederalState_headerAdjusted`
### {.unnumbered}
[Table 5][Population per State at the End of a year] hows the population of all 16 German states on the cutoff date for their coverage. It is not clear from the documentation how the coverage was carried out or whether it is based on an extrapolation. But, since the population figure, according to the cut-off dates, was determined at the end of the year, it represents, in terms of its influence, the respective coming year. Therefore, when importing, the script adjusts the table heading. The result is [Table 6][Population, based on the year before], a structurally identical table, with the same content as the population figures, but no longer for the year in which the figures were recorded, but for the following year. However, the structure of the data set is unsuitable for modeling. Therefore, a change in the table is necessary so that the population figures of the countries per year are included in the regression model as separate observations. This means that the year columns must represent the number of inhabitants in independent entities.

***
```{r ,echo=FALSE, fig.align = "center",  fig.id= TRUE, fig.cap="Pivoting a table into a longer, tidy form^[Fig. 12.2, taken from @GrolemundHadleyWickhamandGarrett.2023 paragraph 12.3.1]"}

knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/3aea19108d39606bbe49981acda07696c0c7fcd8/2de65/images/tidy-9.png")
```
***

One goal of data preparation is gathers, as exemplified by [Figure 2.1](#fig:unnamed-chunk-1) proposed by authors Garrett Grolemund and Hadley Wickham. Applied to the dataset of the Federal Statistical Office, this means that the 7 annual columns per federal state are transformed into one entity. This measure increases the number of rows from `r nrow(population_per_FederalState_headerAdjusted)` to `r nrow(population_per_FederalState_headerAdjusted)*ncol(population_per_FederalState_headerAdjusted)` and results in one column with the year and one with the number of inhabitants.^[cf. @GrolemundHadleyWickhamandGarrett.2023 paragraph 12.3.1] By this measure, the work gains a dataset for modeling later on.

### Cultural Expenditure
```{r Cultural Expenditure, echo=TRUE, message=FALSE, warning=FALSE}


# Missings in Educational Expenditure
## summary is presented with non-scientific numbers, prettyNum() or fomat() was not working for all figures, so it is only used in the textual  areas of this work
#expenditure4Culture_<- expenditure4Culture[expenditure4Culture$CulturalTotalExpenditure,]
table_expenditure4Culture <- addHtmlTableStyle(summary(expenditure4Culture[,c(-(3:6),-9)], maxsum = 20), pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of the expenditures in culture (in €)", label="table_expenditure4Culture")

mean_CulturalExpenditure <- prettyNum(round(mean(expenditure4Culture$CulturalTotalExpenditure)), big.mark = ",",big.interval = 3)
median_CulturalExpenditure <- prettyNum(round(median(expenditure4Culture$CulturalTotalExpenditure)), big.mark = ",",big.interval = 3)

notSeenVariables <- names(expenditure4Culture[,c(3:6,9)])
missings_4_CulturalAffairsAbroad <- expenditure4Culture[is.na(expenditure4Culture$CulturalAffairsAbroad),]
missings_CulturalAffairsAbroad_detailed <- summary(expenditure4Culture[expenditure4Culture$FederalState == "Bremen" | expenditure4Culture$FederalState == "Bayern" | expenditure4Culture$FederalState == "Brandenburg"| expenditure4Culture$FederalState == "Hamburg" | expenditure4Culture$FederalState == "Hessen" | expenditure4Culture$FederalState == "Sachsen"| expenditure4Culture$FederalState== "Sachsen-Anhalt"| expenditure4Culture$FederalState == "Thüringen", c("FederalState","CulturalAffairsAbroad")], maxsum = 20)

table_missings_CulturalAffairsAbroad_detailed <- addHtmlTableStyle(missings_CulturalAffairsAbroad_detailed, pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Detailed analysis of the federal states which contain missing values^[adapted from @StatistischesBundesamtDeutschland.2023c]", label="table_missings_CulturalAffairsAbroad_detailed")
amount_missings_4_CulturalAffairsAbroad <- nrow(expenditure4Culture[is.na(expenditure4Culture$CulturalAffairsAbroad),])

table_Hamburg_Administration4CulturalAffairs <- expenditure4Culture[expenditure4Culture$FederalState == "Hamburg", c("Year", "FederalState","Administration4CulturalAffairs")] %>% addHtmlTableStyle( pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Detailed analysis of the federal states which contain missing values^[adapted from @StatistischesBundesamtDeutschland.2023c]", label="table_Hamburg_Administration4CulturalAffairs")
amount_missings_4_CulturalAffairsAbroad <- nrow(expenditure4Culture[is.na(expenditure4Culture$CulturalAffairsAbroad),])

```
`r table_expenditure4Culture `


In [Table 7](#table_expenditure4Culture), the summary shows both the structure and content composition of cultural expenditures. For each state and each year, data exist, expressed in euros, on the five variables shown here. In addition to these, there are `r notSeenVariables`. In contrast to the variables listed, they have no missing values and are therefore less interesting for consideration. On average, according to the CulturalTotalExpenditure column, countries spent €`r toString(mean_CulturalExpenditure)` on average on culture. Based on the median €`r toString(median_CulturalExpenditure)`, it can be seen that there are countries that skew the average upward. Based on the **NA's**, the table reveals that there are `r amount_missings_4_CulturalAffairsAbroad` data fields with no values for "Cultural Affairs Abroad" among others. In terms of total expenditure, this means that there are potential distortions in the calculation.

`r table_missings_CulturalAffairsAbroad_detailed `

[Table 8](#table_missings_CulturalAffairsAbroad_detailed) shows the content of Cultural Affairs Abroad in more detail. On the one hand, the overview consists of the countries that have missing values and on the other hand, it shows in column two that the maximum of the observations is 0. This means that in the `r nrow(missings_CulturalAffairsAbroad_detailed)` observations, `r amount_missings_4_CulturalAffairsAbroad` with missing value are included, while the remaining observations do not document any expenditure. In this respect, this paper assumes that Cultural Affairs Abroad is not covered by every state or that there are no expenditures in this area. Similar observations and conclusions can be drawn for other states regarding the other spending areas.

`r table_Hamburg_Administration4CulturalAffairs`

Using Hamburg as an example, [Table 9](#table_Hamburg_Administration4CulturalAffairs) illustrates that the findings described in the previous paragraph apply equally to administrative spending in the cultural sector. Thus, the missing values from the summary in [Table 7](#table_expenditure4Culture) indicate that some states have no expenditures in these areas. Based on this knowledge, the paper concludes that the total expenditures of the countries presented do not contain any missing expenditure types, sufficiently summarize cultural expenditures, and are appropriate for inclusion in the regression model. Therefore, for [par. 2.3](#Paragraph2_3), another goal is to extract the total expenditures and add them to the dataset for modeling. 

### Expenditure for Education 
```{r Educational Expenditure, echo=TRUE, message=FALSE, warning=FALSE}

# Summary of the Expenditures for Education
summary_expenditure4Education <- addHtmlTableStyle(summary(expenditure4Education, maxsum = 20), pos.caption = "bottom", align = "left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of expenditure for education^[adapted from @StatistischesBundesamtDeutschland.2023d]", label="summary_expenditure4Education")

## Get the missings
amount_missings_4_expenditure4Education <- nrow(expenditure4Education[is.na(expenditure4Education$TotalExpenditure4Education),])

### Missings in Educational Expenditure
expenditure4Education_missings<- expenditure4Education[is.na(expenditure4Education$TotalExpenditure4Education),]
table_expenditure4Education_missings <- addHtmlTableStyle(head(expenditure4Education_missings), pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Only missings for local authorities expenditures from 3 cities^[adapted from @StatistischesBundesamtDeutschland.2023d]", label="table_expenditure4Education_missings")

### 
# Summary of the Expenditures for Education
summary_expenditure4Education_onlyTotal <- addHtmlTableStyle(summary(expenditure4Education[expenditure4Education$LevelOfSeparation == "Insgesamt",], maxsum = 20), pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of expenditure for education^[adapted from @StatistischesBundesamtDeutschland.2023d]", label="summary_expenditure4Education_onlyTotal")

## Get Median and Mean from the Expenditures for Education


mean_expenditure4Education_onlyTotal <- prettyNum(round(mean(expenditure4Education$TotalExpenditure4Education[expenditure4Education$LevelOfSeparation == "Insgesamt"])), big.mark = ",",big.interval = 3)
median_expenditure4Education_onlyTotal <- prettyNum(round(median(expenditure4Education$TotalExpenditure4Education[expenditure4Education$LevelOfSeparation == "Insgesamt"])), big.mark = ",",big.interval = 3)

difference_median_mean <- prettyNum(round(mean(expenditure4Education$TotalExpenditure4Education[expenditure4Education$LevelOfSeparation == "Insgesamt"]))-round(median(expenditure4Education$TotalExpenditure4Education[expenditure4Education$LevelOfSeparation == "Insgesamt"])), big.mark = ",",big.interval = 3)

```
`r summary_expenditure4Education `

[Table 10](#summary_expenditure4Education) provides a summary of education expenditures, which includes all funds that go to daycare centers, schools, universities, or other training or educational institutions. From 2014 to 2022, three observations represent each state. They arise because the dataset differentiates funds into cumulative **Gemeindeausgaben** (= municiple expenditure), **allgemeine Länderausgaben** (= general state expenditures), and a summarized item of municipalities and states (**zusammenfassenden Position**). Because of this differentiation, it is not yet meaningful to look at the median and average expenditures. However, the number of `r toString(amount_missings_4_expenditure4Education)` missing entries is striking.

`r table_expenditure4Education_missings`

Looking at the missing in [Table 11](#table_expenditure4Education_missings), it is clear that the states of *Berlin, Bremen, and Hamburg* do not report any municipal expenditures. This is because these federal states are city states and thus are municipalities and federal states at the same time. Due to this peculiarity, it does not make sense to look at the individual municipal expenditures. The paper therefore focuses on the observations documenting the total expenditures of the states.

`r summary_expenditure4Education_onlyTotal`
The adjusted [Table 12](#summary_expenditure4Education_onlyTotal) now shows the total expenditures of the Federal States and exposes their statistical peculiarities. Despite focusing on the total expenditures, a considerable difference of `r toString(difference_median_mean)` between the median `r toString(median_expenditure4Education_onlyTotal)` and the arithmetic mean `r toString(mean_expenditure4Education_onlyTotal)` emerges.The impact of this difference is illuminated in [Chapter 3](#Chapter3). In addition, there is a variable for the expenditures per person of the Federal States, but this is not used in the paper because it already considers the number of inhabitants. Regarding education expenditures, the task for [par. 2.3](#Paragraph2_3) is to extract the total expenditures of a country and to restrict them to the years 2014 to 2020. 
limited.

### Number of Unemployed People
```{r unemployment rate, echo=TRUE, message=FALSE, warning=FALSE}

# Shows the amount of unemployees in each federal state 
summary_Unemployment <- summary(jobless_people[,1:8]) %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left" ) %>% htmlTable(rnames=FALSE, caption="No missings in the table and  the structre shows federal states as colums^[adapted from @StatistischesBundesamtDeutschland.2023b]", label="summary_Unemployment")

```
`r summary_Unemployment`

Similar to the data set for inhabitants, the data set for the number of unemployed people is structured. In this case, according to [Table 13](#summary_Unemployment), one variable is available for the years, while the number of unemployed people is spread over several columns as a variable per state. Due to an abbreviated presentation, [Table 13](#summary_Unemployment) does not present all federal states with their figures. For a more profound understanding of the problem, [Appendix 3][Appendix 3] lists a complete overview. To perform a regression modeling, a pivoting as in [Figure 2.1](#fig:unnamed-chunk-1) has to be done for the federal states. This means that [par. 2.3](#Paragraph2_3) is given the additional task of presenting the states and the number of unemployed as a separate variable. This results in an observation with the variables for the year, the federal state and the number of cases.

### Gross Domesti Product 
```{r gross domestic product, echo=TRUE, message=FALSE, warning=FALSE}

# Gross Domestic Product is structured similar to the inhabitants
summary_gdp<- summary(gdp_atMarketPrice[,1:7]) %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="No missings in the GDP-table and the structre is similar to the inhabitant^[adapted from @StatistischesBundesamtDeutschland.2023e]", tfoot =  "Figures are presented in Euro and only until 2019.", label="summary_gdp")

mean_gdp2014 <- prettyNum(round(mean(gdp_atMarketPrice$`2014`)), big.mark = ",",big.interval = 3)
mean_gdp2019 <- prettyNum(round(median(gdp_atMarketPrice$`2019`)), big.mark = ",", big.interval = 3)

```
`r summary_gdp`

Finally, [Table 14](#summary_gdp) provides an insight into the contributions of the individual states to the gross domestic product (GDP). The summary implies, on the one hand, a complete data set, since no "NAs" are named. On the other hand, the structure of the data results in identical targets for [par. 2.3](#Paragraph2_3) as for the population figures. At the substantive level, [Table 14](#summary_gdp) shows that economic strength is increasing through 2019. In 2014, the gross domestic product averaged €`r mean_gdp2014`, 5 years later it was €`r mean_gdp2019`. However, whether an impact on criminal cases exists can only be determined after pivoting, as the annual data is not available as a stand-alone variable. This circumstance causes the data in its current form to represent multiple entities in one row, preventing modeling.

In summary, this section showed that the datasets for the population/unemployment and gross domestic product figures structurally have a similar need for action. The datasets for cultural and educational expenditures are broken down in detail, but are not needed in this way. They also show gaps in some observations that are logically justified and do not affect the relevant variables. Thus, the listed structural and content peculiarities result in the following objectives for the data preparation in [par. 2.3](#Paragraph2_3):
<br>
<ul>
* Pivoting of the population, unemployment, and GDP tabulations so that observations with the variables' year, state, population/unemployment/gross domestic product emerge.
* Extraction of total cultural expenditures, excluding expenditures per type of culture.
* Extraction of total education expenditures for the years 2014 to 2020, exclusion of expenditures per inhabitant
* Merging of all data sets regarding regression modeling
</ul>

***
##	Data preparation {#Paragraph2_3}
From the previous two sections ([par. 2.1](#Paragraph2_1)) and ([par. 2.2](#Paragraph2_2)), various extraction and transformation tasks emerged for this section. They possess the goal of producing a data set for regression modeling. First, this section devotes its attention to the data of the Federal Criminal Police Office. The most important task is to select the total number of thefts per state and year and to merge them into one table. Moreover, an additional variable is added to the data set, which divides the federal states into four categories according to their size. This assignment is used later in the regression analysis to account for constant effects and to improve the significance.

### Prepraration of the criminal statistic data

```{r PKS-Data-Preparation, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Add Variable Year to Dataset and combines them to one Dataset
source("./00_Skripte/combineAllYears.r", local = knitr::knit_global())

## Creats a summary table for the new Dataset
summary_Cases<- summary(caseNumbers_allYears_transformed4Summary, maxsum = 10) %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of all yearly reports of crimecases^[adapted from @Bundeskriminalamt.2023]", tfoot =  "Shows the years as factors to visualise the amount of observerations per year. Furthermore there are many different crimetypes listed, but necessary is only  **\"Diebstähle insgesamt und zwar\"** as mentiond in [par. 2.1](#Paragraph2_1) " , label="summary_Cases")

summary_Cases
# Select Observation for Thefts , Rename Casenumbers to TheftAmount, Rename Federalstates with vowel ü, Drop Column CrimeKey and Crimetype, Drop Observation for whole Germany, 
source("./00_Skripte/varSelection_caseNumbers.r", local = knitr::knit_global())

summary_thefts<- summary(thefts_allYears_transformed4Summary, maxsum = 25) %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of all yearly reported thefts from 2014 until 2020^[adapted from @Bundeskriminalamt.2023]", label="summary_thefts")

```

The first script, *combineAllYears.r*combines all individual data sets from 2014 to 2020 into one. [Table 15](#summary_Cases) illustrates the result and shows a section of it. Since the focus of the work is on thefts, it becomes apparent that the dataset contains many irrelevant observations. Therefore, the script *varSelection_caseNumbers.r* transfers the case numbers of thefts into a new variable **thefts_allYears_tidy**. Due to the extraction of a specific crime type, the relevance of the columns **Crimetype** and **CrimeKey** is subsequently omitted. Therefore, the script removes these variables from the dataset. At the same time, it removes the last inconsistencies and further surpluses in the dataset, for example for the states Baden-W**ü**rttemberg and Th**ü**ringen, which each have two characteristics because of the umlaut **"ü"**. For a complete view of the summary, see [Appendix 4][Appendix 4].

`r summary_thefts`

[Table 16](#summary_summary_thefts) presents the final version of the merge. Here, **thefts_allYears_transformed4Summary** is used to illustrate the number of observations per year. This is equally distributed in the dataset, as each year, state, and group of states contains the same number of observations. For data processing and regression modeling, the year counts are still available as discrete metric data.

```{r , echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.id= TRUE, fig.cap="Mean & Median Development of thefts grouped by their Areasize of the Federal States"}
grouped_mean_thefts_by_areasize <- thefts_allYears_tidy %>% group_by(Year, Areasize) %>% summarise(TheftAmount = mean(TheftAmount))

theft_mean_developement <- ggplot(data = grouped_mean_thefts_by_areasize, aes(x = Year, y = TheftAmount, group = Areasize , color=Areasize)) +
  geom_line(size = 1) +
  scale_color_discrete(labels = c('Big (BY, BW, NW, NI)', 'Medium (BB, HE, ST, MV)', 'Small (SN, RP, TH, SH)', 'Very Small (SL, HH, BE, HB)')) +
  labs(x = "Year of Documentation", y = "Amount of Thefts" )+ 
  theme( plot.title = element_text(hjust = 0.5, size = 10, color = "black"), axis.title.y = element_text(size = 8, colour = "darkgrey"), axis.title.x = element_text(size = 8, colour = "darkgrey"))+
  theme(legend.position=c(0,.45), legend.justification =c(0,0.5), legend.text = element_text(size = 8, colour = "black"), legend.title =  element_text(size = 10), legend.background = element_rect(colour = "transparent", fill = alpha("grey", 0)))  +
  ggtitle("Mean-Development of thefts")

grouped_median_thefts_by_areasize <- thefts_allYears_tidy %>% group_by(Year, Areasize) %>% summarise(TheftAmount = median(TheftAmount))

theft_median_developement <- ggplot(data = grouped_median_thefts_by_areasize, aes(x = Year, y = TheftAmount, group = Areasize , color=Areasize)) +
  geom_line(size = 1) +
  scale_color_discrete(labels = c('Big (BY, BW, NW, NI)', 'Medium (BB, HE, ST, MV)', 'Small (SN, RP, TH, SH)', 'Very Small (SL, HH, BE, HB)')) +
  labs(x = "Year of Documentation", y = "Amount of Thefts" )+ 
  theme(legend.position = "none",plot.title = element_text(hjust = 0.5, size = 10, color = "black"), axis.title.y = element_blank(), axis.title.x = element_text(size = 8, colour = "darkgrey"))  +
  ggtitle("Median-Development of thefts")

maxMean_thefts_of_one_federalState <- prettyNum(round(max(grouped_mean_thefts_by_areasize$TheftAmount)), big.mark = ",", big.interval = 3)

maxMedian_thefts_of_one_federalState <- prettyNum(round(max(grouped_median_thefts_by_areasize$TheftAmount)), big.mark = ",", big.interval = 3)

grid.arrange(ncol=2, theft_mean_developement,theft_median_developement, widths = c(1, 0.95))
```

Grouping the states by their state size allows for a graphical view of the number of cases. [Figure 2.2](#fig:unnamed-chunk-2) outlines on the left that **big** states have a higher number of thefts than others. This is also confirmed by the media of the grouped observations. However, it is important to note the difference between the median (right) with `r toString(maxMedian_thefts_of_one_federalState)` and the arithmetic mean (left) with `r toString(maxMean_thefts_of_one_federalState)` thefts, starting from 2014. In addition, it is noticeable that **very small**, compared to **medium** and **small** states on average, have a higher number of thefts. However, the median in the chart on the right suggests that this phenomenon causes an outliner.

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE,  fig.id= TRUE, fig.cap="Distribution of Theafts among each group of Federal States"}

## ggarange http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/81-ggplot2-easy-way-to-mix-multiple-graphs-on-the-same-page/  ---> Tabelle muss umgewandelt werden, so dass durchschnitt erhobenwird
thefts_bp_2014 <- ggplot(data = thefts_allYears_tidy[thefts_allYears_tidy$Year == 2014, ], aes(y = TheftAmount, x=Areasize, color=Areasize, legend.p)) +
  geom_boxplot(size = 0.5) + 
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, size = 10,color = "black")) + 
  theme(axis.title.x = element_blank(),  axis.title.y = element_text(color = "grey", size = 8))+ 
  labs(y = "Amount of Thefts" ) + 
  ggtitle("2014")

thefts_bp_2015 <- ggplot(data = thefts_allYears_tidy[thefts_allYears_tidy$Year == 2015, ], aes(y = TheftAmount, x=Areasize, color=Areasize)) +
  geom_boxplot(size = 0.5) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, size = 10, color = "black")) + 
  theme(axis.title.x = element_blank(),  axis.title.y = element_blank())+
  ggtitle("2015")

thefts_bp_2019 <- ggplot(data = thefts_allYears_tidy[thefts_allYears_tidy$Year == 2019, ], aes(y = TheftAmount, x=Areasize, color=Areasize)) +
  geom_boxplot(size = 0.5) + 
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, size = 10, color = "black")) +
  theme(axis.title.x = element_text(color = "grey", size = 8),  axis.title.y = element_text(color = "grey", size = 8))+ 
  labs(x = "Areasize of the Federal States", y = "Amount of Thefts" )+ 
  ggtitle("2019")


thefts_bp_2020 <- ggplot(data = thefts_allYears_tidy[thefts_allYears_tidy$Year == 2020, ], aes(y = TheftAmount, x=Areasize, color=Areasize)) +
  geom_boxplot(size = 0.5) + 
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, size = 10, color = "black"))  +
  theme(axis.title.x = element_text(color = "grey", size = 8),  axis.title.y = element_blank()) + 
  labs(x = "Areasize of the Federal States") +
  ggtitle("2020")

grid.arrange(ncol=2, thefts_bp_2014, thefts_bp_2015, thefts_bp_2019, thefts_bp_2020)

```

Box plots are used to show the distribution of thefts within their groups, but since the groups are represented by only 4 observations per year, their significance is limited. However, [Figure 2.3](#fig:unnamed-chunk-3) supports the understanding of the dispersion of the thefts in the respective groups. The upper left graph shows a wide spread of theft figures for the **big** states (red) in 2014. The median is about `r toString(maxMedian_thefts_of_one_federalState)` thefts and there is one outlier. This explains the higher average in [Figure 2.2](#fig:unnamed-chunk-2). Compared to the other box plots, this is a significant difference. Furthermore, the scattering of observations in the **very small** states is striking. The number of thefts exceeds that of the larger states and shows a wide range.

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.a = "center",  fig.id= TRUE, fig.cap="Development of the Casenumbers in each Federal State"}

thefts_development_fS <- ggplot(data = thefts_allYears_tidy, aes(x = Year, y = TheftAmount, group = FederalState , color=FederalState)) +
  geom_line(size = 1) +
  geom_text_repel(aes(label = FederalState), data = thefts_allYears_tidy[thefts_allYears_tidy$FederalState %in% c("Nordrhein-Westfalen","Berlin", "Saarland") & thefts_allYears_tidy$Year==2020,], fontface ="plain", color = "black", size = 3 ) +
  theme(plot.title = element_text(hjust = 0.5, size = 10, color = "black"), legend.text = element_text(size = 8, colour = "black"),legend.title =  element_text(size = 10)) +
  theme(axis.title.x = element_text(color = "grey", size = 8),  axis.title.y = element_text(color = "grey", size = 8))+ 
  labs(x = "Year of Documentation", y = "Amount of Thefts")+
  scale_colour_discrete(name  ="Federal States")
thefts_development_fS 

mean_thefts_of_NRW <- prettyNum(round(mean(thefts_allYears_tidy$TheftAmount[thefts_allYears_tidy$FederalState == "Nordrhein-Westfalen"])), big.mark = ",", big.interval = 3)

mean_thefts_of_notNRW <- prettyNum(round(mean(thefts_allYears_tidy$TheftAmount[!(thefts_allYears_tidy$FederalState == "Nordrhein-Westfalen")])), big.mark = ",", big.interval = 3)



```

An individual analysis of the states in [Figure 2.4](#fig:unnamed-chunk-4) illustrates the observations. North Rhine-Westphalia has the highest number of thefts, with over `r toString(mean_thefts_of_NRW)` cases. This figure differs significantly from the case numbers of other **big** states, which average around `r toString(mean_thefts_of_notNRW)`. The high range from [Figure 2.3](#fig:unnamed-chunk-3) in the **very small** states is the result of the noticeably higher case numbers from Berlin and the lower case numbers from Saarland. Bremen and Hamburg are exactly in the middle, which is why the median plotted in [Figure 2.3](#fig:unnamed-chunk-3) hardly differs from the two next largest groups of states, but the average plotted in [Figure 2.2](#fig:unnamed-chunk-2) has a higher value. The significance of these peculiarities is not discussed until [Chapter 4](#Chapter4). The next part of the section pursues the objectives from [par. 2.2](#Paragraph2_2) and deals with the specific data of the federal states.

### Preparation of specific data from the Federal States 
```{r pivoting extract exclude, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Script pivotes, extracts and transforms the data as needed. Additionally it merges the Data together based on the Year and Federal State
source("./00_Skripte/prepareFederalStateData.r", local = knitr::knit_global())

summary_pivotated_Population <- tidyTable_of_population %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of all yearly reported inhabitants from 2014 until 2020 in each federal state^[adapted from @StatistischesBundesamtDeutschland.2023]", label="summary_pivotated_Population")

## for text - changes as row length
populationLength_after <- nrow(tidyTable_of_population)
populationLength_before <- nrow(population_per_FederalState_headerAdjusted)


# Summary of all Datasets as merged Data
summary_mergedData <- summary(mergedData4regression) %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of the merged data", tfoot =  "The data includes the federal states, their grouping by areasize and the tracked years as dummy variable, the number of thefts as the dependent variable and each specific independent variable from the number of inhabitant to the expenditures for culture. The presentation of the values in a non-scientific way was prefered from this work as it shows the diffrences among the variables.", label="summary_mergedData")

pretty_maxPopulation <- prettyNum(max(mergedData4regression$Population), big.mark = ",",big.interval = 3)
pretty_meanJobless <- prettyNum(round(mean(mergedData4regression$AmountOfUnemployedPeople)), big.mark = ",",big.interval = 3)
pretty_minGDP <- prettyNum(min(mergedData4regression$GDP),big.mark = ",",big.interval = 3)
pretty_maxGDP <- prettyNum(max(mergedData4regression$GDP), big.mark = ",",big.interval =3)
pretty_medianEduExp <- prettyNum(median(mergedData4regression$TotalExpenditure4Education), big.mark = ",",big.interval = 3)
pretty_medianCultExp <- prettyNum(median(mergedData4regression$CulturalTotalExpenditure), big.mark = ",",big.interval = 3)
pretty_spanThefts <- prettyNum(max(mergedData4regression$TheftAmount)-min(mergedData4regression$TheftAmount), big.mark = ",",big.interval = 3)


```
The last script of the data preparation performs the transformations and extractions listed in [par. 2.2](#Paragraph2_2). Among other things, it reshapes the data structure for regression analysis. For example, it performs the pivoting of the population, unemployment and GDP tables, so that the observations organize their values per year and per state.

`r summary_pivotated_Population`
The result of the pivoting is shown by the population figures in [Table 17](#summary_pivotated_Population). In the table, there is a column for the state, the year, and the number of inhabitants. In total, the length grew from `r populationLength_before` rows to `r populationLength_after` (see [Table 5][Population per State at the End of a year] or [Table 6][Population, based on the year before]). As an aside, the total figures for the Federal Republic were removed, as they are irrelevant for the analysis.

`r summary_mergedData`

The extraction of the data has already been demonstrated before embedding it into the scripts in section [par. 2.2](#Paragraph2_2). In the script, the selection methods are used to merge their output into new variables. During execution, the script successively merges the increments into the **mergedData4regression** dataset. Included in the procedure are cleanups and adjustments to the data format of the variables. The result is summarized in [Table 18](#summary_mergedData).^[It should be noted at this point that the work prefers a regular representation of the numbers to visually show the differences between the variables and their magnitude. Textually, the representation is supported by interval points.] The dataset contains one observation per year for each federal state and is additionally placed in one of four groups with other federal states according to their respective area. The population reflects the number of inhabitants. The highest population ever measured in a federal state, in the period from 2014 to 2020, is `r pretty_maxPopulation`. On average, `r pretty_meanJobless` of Germany's residents were unemployed. The gross domestic product ranges between the federal states from €`r pretty_minGDP` to €`r pretty_maxGDP`. Thus, it shows the largest amounts of billions in comparison to the expenditures for education and culture. On average, spending on education was €`r pretty_medianEduExp` and on culture €`r pretty_medianCultExp`. The extent to which there is a correlation between the figures and the range of `r pretty_spanThefts` theft cases is determined in the following section by the regression analysis presented.

***
##	Modeling by using linear regression {#Paragraph2_4}
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library("plm")
library("lmtest")
library("car")

mergedData4regression$Year <- as.factor(mergedData4regression$Year)

### Short variablenames are needed because stargazer can not work with longer Variable names
regMod_1 <- lm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure, data=mergedData4regression[,-1])


regMod_2 <- lm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure + Areasize + Year  -1, data=mergedData4regression[,-1])

#Alternativly done with plm
## regMod_2 <- plm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure, data=mergedData4regression[,-1], index = c( "Areasize","Year"), model = "within", effect = "twoways")

regMod_3 <- lm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure + FederalState + Year -1, data=mergedData4regression[,-4])
#Alternativly done with plm
## regMod_3 <- plm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure, index = c("FederalState", "Year"), model = "within", effect = "twoways", data=mergedData4regression[,-4])

```

Based on the **mergedData4regression** dataset prepared in [par. 2.3](#Paragraph2_3), this paragraph, performs the regression analysis. The code chunk above computes three models. The reason for three models is the unknown influence of the control variables and their aggregation. The first model does not include fixed effects. The second and third models include control variables in the analysis. The control variable is the annual data and, additionally, either the countries as a separate entity (model 3) or as groups of countries according to their size (model 2). For the calculation, the work uses the method *"lm()"* from the package *"lmtest"*. The method *plm()* can be used alternatively, but it was not selected because it considers the control variables in the model calculation but does not output them, this caused some distortions during the investigation.

### Equations of each regression model  {.unnumbered .tabset .tabset-fade}

#### Model 1 {-}

$$ 
\begin{split}
TheftAmount & \sim \beta_0 \\
& + \beta_1*Population  \\
& + \beta_2*GDP  \\
& + \beta_3*AmountOfUnemployedPeople  \\
& + \beta_4*TotalExpenditure4Education   \\
& + \beta_5*CulturalTotalExpenditure \\
\end{split}
(\#eq:equation)
$$

#### Model 2 {-}

$$ 
\begin{split}
TheftAmount & \sim \beta_0*Population  \\
& + \beta_1*GDP  \\
& + \beta_2*AmountOfUnemployedPeople  \\
& + \beta_3*TotalExpenditure4Education   \\
& + \beta_4*CulturalTotalExpenditure \\
& + \gamma_0*AreaSize0 + ... +  \gamma_3*AreaSize3 \\
& + \delta_0 *Year0 ... \delta6*Year6
\end{split}
(\#eq:equation)
$$

#### Model 3 {-}

$$ 
\begin{split}
TheftAmount & \sim \beta_0*Population  \\
& + \beta_1*GDP  \\
& + \beta_2*AmountOfUnemployedPeople  \\
& + \beta_3*TotalExpenditure4Education   \\
& + \beta_4*CulturalTotalExpenditure \\
& + \gamma_0*FederalState0 + ... +  \gamma_15*FederalState16 \\
& + \delta_0 *Year0 ... \delta6*Year6
\end{split}
(\#eq:equation)
$$

### {-}
The formulas in [2.1](#eq:equation) demonstrate the structure of the respective regression models. The first model omits control variables and describes the relationship to the number of cases as the sum of the population, gross domestic product, unemployment, and spending on education and culture. Furthermore, the regression coefficients $\beta_0$ influence to $\beta_5$ the effect of the independent variables. The second and third models introduce the above control variables to reduce bias on the independent variables. They take the value of 0 or 1 as dummy variables and are represented by the parameters $\gamma_n$ or $\delta_n$ influenced.

In conclusion, [chapter  2](#Chapter2) showed that the data from the Federal Criminal Police Office as well as those from the Federal Statistical Office require some processing. [par. 2.1](#Paragraph2_1) and [par. 2.2](#Paragraph2_2) narrowed down the data, to the variables and observations relevant to the research question. [par. 2.3](#Paragraph2_3) extracts the variables relevant to the research question. These include the number of thefts per state as the dependent variable and the various independent variables, from population to total spending on culture. In addition, the section describes that the states, grouped by their area, each have different peculiarities in the mass of thefts or their range. How the independent variables explain these peculiarities is described by the regression models set up in [par. 2.4](#Paragraph2_4), with two of the three models including various control variables, which [chapter  3](#Chapter3) considers in more detail.

***
#	Analysis & Results {#Chapter3}
```{r analysis,echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}


# Only partially presented in the text, the whole output can be seen in the appendix 5
rM1_coeftest <- coeftest(regMod_1, vcov = vcovHC, type = "HC1")

rM1_F_Test <- linearHypothesis(regMod_1,
                 test = "F",
                 c("AmountOfUnemployedPeople=0", "TotalExpenditure4Education=0", "CulturalTotalExpenditure=0"), 
                 vcov. = vcovHC, type = "HC1")

rM2_coeftest <- coeftest(regMod_2, vcov = vcovHC, type = "HC1")

rM2_F_Test <-linearHypothesis(regMod_2,
                 test = "F",
                 c("AmountOfUnemployedPeople=0", "TotalExpenditure4Education=0", "CulturalTotalExpenditure=0"), 
                 vcov. = vcovHC, type = "HC1")
rM2_F_Test2 <- linearHypothesis(regMod_2,
                 test = "F",
                 c("Population=0", "GDP=0", "AmountOfUnemployedPeople=0", "TotalExpenditure4Education=0", "CulturalTotalExpenditure=0"), 
                 vcov. = vcovHC, type = "HC1")

rM3_coeftest <- coeftest(regMod_3, vcov = vcovHC, type = "HC1")

rM3_F_Test1 <- linearHypothesis(regMod_3,
                 test = "F",
                 c("AmountOfUnemployedPeople=0", "TotalExpenditure4Education=0", "CulturalTotalExpenditure=0"), 
                 vcov. = vcovHC, type = "HC1")
rM3_F_Test2 <- linearHypothesis(regMod_3,
                 test = "F",
                 c( "Population=0", "GDP=0", "CulturalTotalExpenditure=0"), 
                 vcov. = vcovHC, type = "HC1")


# Paragraph will generate table for overview

#library(stargazer) not used because not adjustable caption with numeration
# gather clustered standard errors in a list
#theftsModel_se <- list(sqrt(diag(vcovHC(regMod_1, type = "HC1"))),
               # sqrt(diag(vcovHC(regMod_2, type = "HC1"))),
               # sqrt(diag(vcovHC(regMod_3, type = "HC1"))))

#stargazerExample <- stargazer(regMod_1, regMod_2,regMod_3, regMod_4,regMod_5, digits = 6,type = "html", title = "Linear Modells", header = FALSE,se = theftsModel_se, add.lines = list(c("Control Variables", "No", "Yes", "Yes", "Yes", "Yes")),model.numbers = FALSE, column.labels = c("(1)", "(2)", "(3)", "(4)","(5)" ), label = "stargazerExample")

library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(rvest)

#Creating a table for all of the models
## tab_model has to be executed before you knit the rmarkdown, it stores a the HTML-File which will be used later by read_html(). Unfortunately it does not create the HTML during knitting the document, that's why this Workaround has to be used.
createOverview <- tab_model(regMod_1, regMod_2,regMod_3, 
          vcov.fun = "HC1",  p.style = "stars" ,digits = 6, 
          show.df = FALSE, show.fstat = TRUE, show.ci = FALSE,
          dv.labels = c("Model 1", "Model 2", "Model 3"), 
          file= "./02_VerarbeiteteDaten/zusammenfassung.html", encoding = "latin") 

Overview_RegModels <- read_html("./02_VerarbeiteteDaten/zusammenfassung.html") %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(caption="Overview of all regression modells shows Model 3 as best result", tfoot =  "All regression models from [par. 2.4](#Paragraph2_4) present significant estimators for  some of their variables, but the third model has a better adjusted R² and also includes control variables. Hence it is the most exact model for the data that was used. It leads to the conclusion that expenditures for education are negatively related to the number of thefts. The more federal states invest in education, the fewer thefts appear." , label="Overview_RegModels")

Overview_RegModels

```
The regression analysis yields the coefficients listed in [Table 19](#Overview_RegModels). For a wide variety of independent variables, they show that there is a correlation between the various country-specific variables and the number of cases of theft. The models differ in the amount of control variables used, and the variables evaluated as significant. For example, the first model does not include any control variables and declares all independent variables as significant. However, it does not consider constant effects in the states or specific effects from the respective years.

$$ 
\begin{split}
TheftAmount & \sim `r toString(regMod_2[1]$coefficients["Population"])`*Population  \\
& + `r toString(round(regMod_2[1]$coefficients["GDP"], digits=7))`*GDP  \\
& + `r toString(round(regMod_2[1]$coefficients["AmountOfUnemployedPeople"], digits=7))`*AmountOfUnemployedPeople  \\
& + (`r toString(round(regMod_2[1]$coefficients["TotalExpenditure4Education"], digits=7))`)*TotalExpenditure4Education   \\
& + `r toString(round(regMod_2[1]$coefficients["CulturalTotalExpenditure"], digits=7))`*CulturalTotalExpenditure \\
& + (`r toString(round(regMod_2[1]$coefficients["Areasizebig"], digits=7))`)*AreaSize0 + ... +  `r toString(round(regMod_2[1]$coefficients["Areasizevery small"], digits=7))`*AreaSize3 \\
& + `r toString(round(regMod_2[1]$coefficients["Year2015"], digits=7))`*Year0 + ... + (`r toString(round(regMod_2[1]$coefficients["Year2020"], digits=7))`)*Year6
\end{split}
(\#eq:equation2)
$$
[Equation 3.1](#eq:equation2) uses Model 2 to illustrate how the interpretation of [Table 19](#Overview_RegModels) is implemented as a formula. The use of control variables changes the evaluation of the regression coefficients, as distortions due to effects not considered are reduced.^[cf. @ChristophHanckMartinArnoldAlexanderGerberandMartinSchmelzer.2023] For example, the significance level for the coefficients of gross domestic product and population is not reached. Only the unemployment rate and spending on education and culture have a significant effect on the number of thefts. In the interpretation of the coefficients, the model assumes that
<ul>
* the increase in the number of unemployed by one person is related to an approximately equal increase in thefts.
* the investment in education per €100,000 is related to a decrease of 2.3 cases.
* the expenditure on culture per €100.000 is correlated with an increase of 8,6 thefts.
</ul> 

The last point is contrary to the hypothesis of the work. The hypothesis supposed a negative, rather than a positive, correlation between culture spending and thefts. Consequently, the first two points are consistent with the assumption of the research. The gross domestic product and the number of inhabitants, which do not show a significant effect, fall completely out of the hypothesis. Accordingly, the alternative hypothesis now includes three variables instead of five and is opposed to the null hypothesis.

```{r significance_model_2, echo=TRUE, fig.cap="Rejection of the null hypothesis in favor of the 2nd model by reaching a high level of significance", fig.subcap="All results form t- and F-Test can be seen in [Appendix 5][Appendix 5]", message=FALSE, warning=FALSE, paged.print=FALSE}
rM2_F_Test
```

**rM2_F_Test** uses *linearHypothesis()*, a method used in the previous [Chunk][#Chapter3], to test the significance of the model. The **F-Test** yields a **p-Wert** < 0.01, rejecting the null hypothesis. It indicates that a regression model with the unemployment rate and education and culture expenditures is better for prediction than a model imputing no effects to the factors. (See [Appendix 5][Appendix 5] for additional **t-test** and **F-Test** results).

```{r significance_model 3, echo=TRUE, fig.cap="t-Test for Model 3 consideres heteroscedasticity and autocorrelation and shows only expenditure for education as signicant ", fig.subcap="All results form t- and F-Test can be seen in [Appendix 5][Appendix 5]", message=FALSE, warning=FALSE, paged.print=FALSE}
## Checks Standarderror, value of Model 2 is twice as high as the value of model 3
r_squard_model3 <- round(summary(regMod_2)$adj.r.squared, digits=3)
SE_model2 <- round(summary(regMod_2)$sigma, digits = 2)
SE_model3 <- round(summary(regMod_3)$sigma, digits = 2)

# Checks significance of regression coefficients of the independent variables from model 3
rM3_coeftest
```

Additionally, the paper examines the coefficient of determination R² from [Tab. 19](#Overview_RegModels). With a adjusted R² of `r  toString(r_squard_model3)`, Model 3 achieves the best result based on the data examined through its control variable for each state. This is also shown by the standard error, which in model 2 is `r toString(SE_model2)` and thus twice as high as model 3 with `r toString(SE_model3)`. Considering this, the result from model 3 is preferred. From the result of the **t-Test** from **rM3_coeftest**, the variable for education spending stands out as the only significant variable. (See [Appendix 5][Appendix 5] for all **t-test** and **F-Test** results.) From the effect of the regression coefficient, the paper concludes that countries that have about one million euros more education spending than other countries have about 28 fewer theft cases. It remains questionable, however, whether this effect is actually relevant for a federal state and whether this interpretation stands up to critical scrutiny in [Chapter 4](#Chapter4).

***
#	Discussion: biases and limitations {#Chapter4}

As mentioned in the previous chapter, the calculated significant effect of education according to model 3 is `r toString(round(regMod_3[1]$coefficients["TotalExpenditure4Education"], digits=7)*10^6)` thefts per million €. If this effect is indeed based on a causal relationship, then the investment cost in education is €`r toString(-10^6/(round(regMod_3[1]$coefficients["TotalExpenditure4Education"], digits=7)*10^6))` to prevent one theft each. This cost compares with the average damage to €1,232 caused by one theft per person.^[adapted from @StatistischesBundesamtDeutschland.2023] From this cost perspective, it follows that there is probably no relevant relationship for practice. However, it should be noted that this simplified calculation does not take into account the costs of law enforcement and prosecution per theft and therefore requires separate consideration.

In addition, a review of the general regression model assumptions as described by Zuckarelli revealed that the residuals of the models are not equally distributed. As the aggregation of the states decreases, the residuals deviate from the normal distribution. This means that the significance of the estimators and the model cannot be determined by the **t-test** and **F-Test**.^[cf. @Zuckarelli.2017 p. 232]

```{r echo=TRUE, fig.cap="QQ-Test shows not normal distributed residuals for both models", fig.subcap="QQ-Tests are important to prove the meaningfullness of the Significance-Test-Results. Deviations from the dotted line can be seen in both graphs; the more the residuals deviate from it, the less normally distributed they are.", message=FALSE, warning=FALSE, paged.print=FALSE}
# Test for normal distributed residuals
## Grafik shows not normal distributed residuals --> t- and F-Tests can be biased!

par(mfrow=c(1,2))
plot(regMod_2, which=2)
title(main = "Model 2", cex.main=1)
plot(regMod_3, which=2) 
title(main = "Model 3", cex.main=1)
## Validation of the grafical results via Jarque-Bera-test --> t- und F-test-Results have a little meaningfulness (p. 232 Statistik mit R) --> Test shows a non-normal distribution due to outliers --> countermeasure increase sample size or introduce robust estimates, maybe another form of aggregation or grouping of the entities may also be helpful
library(tseries)
jb_test_model2 <- jarque.bera.test(regMod_2$residuals)
jb_test_model3 <- jarque.bera.test(regMod_3$residuals)
jb_test_model2_p <- round(jb_test_model2$p.value, digits = 4)
jb_test_model3_p <- round(jb_test_model3$p.value, digits = 15)
## Check Autocorrellation with dwtest --> no autocorrelation, no discussion needed in this paper
autokorrelation_model2 <-dwtest(regMod_2)
autokorrelation_model3 <- dwtest(regMod_3)
```
[Figure 4.1](#fig:unnamed-chunk-6) illustrates the distribution problem by the greater distance of the data points at the quantile line. In Model 2, which looks at the states grouped by size, the data points are closer to the normal distribution than in Model 3. The *Jarque-Bera-Test* confirms this impression, with significant results for Model 2 (p = `r toString(jb_test_model2_p)`) and Model 3 (p = `r toString(jb_test_model3_p)`).

Outliers, such as North Rhine-Westphalia in the **big** and Berlin in the **very small** state groups (see [Figure 2.4](#fig:unnamed-chunk-2)) offer a potential explanation and clues for optimization. Aggregation by size does not appear to be useful for modeling because of the range, as shown in [Figure 2.3](#fig:unnamed-chunk-3). Moreover, embedding the states as dummy variables (Model 3) requires more observations than just seven observations per state. For this reason, the significance of the coefficients must be evaluated cautiously.

Furthermore, the underlying regression function must be critically evaluated. The problem is illustrated by model 2, as shown in [Equation 3.1](#eq:equation2). A decrease in the unemployment rate is accompanied by a roughly equal decrease in the theft rate. All German states with more unemployed people than thefts theoretically have negative theft rates above a certain threshold when the unemployment rate reaches this value. Thuringia can hypothetically fall below this threshold at `r toString(mergedData4regression[mergedData4regression$FederalState == "Thueringen" & mergedData4regression$Year == 2020, "AmountOfUnemployedPeople"])` unemployed if the number drops to `r toString(mergedData4regression[mergedData4regression$FederalState == "Thueringen" & mergedData4regression$Year == 2020, "TheftAmount"]-1)`.

In summary, the regression analysis probably showed little relevant results. Even if more in-depth considerations would show relevance, the paper doubts the significance of the regression coefficients and the model due to the non-normally distributed residuals. Finally, the regression function used does not stand up to critical scrutiny either. Nevertheless, [chapter 5](#Chapter5) offers some optimization possibilities that can be used in future studies.

***
#	Conclusion: findings and implications {#Chapter5}
The critical review in [chapter 4](#Chapter4) revealed sufficient reasons to reject the regression models. The second regression model does suggest in [chapter 3](#Chapter3) that the unemployment rate and spending on education and culture have a significant relationship and partially confirms the hypotheses from. However, the results come into doubt due to the Jarque-Bera-Test and the improper function. The same applies to model 3, which only attests to a supposed significance for education spending. Regardless of the doubtful significance, there is no relevance from a cost perspective for the variable education expenditures, with a coefficient of `r toString(round(regMod_3[1]$coefficients["TotalExpenditure4Education"], digits=7)*10^6)` thefts per million €.

The hypotheses that were in the room at the beginning of the paper cant be tossed aside yet. The application of a probit/logit model  in future investigations eliminates the weaknesses of the applied linear regression function. In addition, countermeasures, such as thoughtful outlier management or increasing the sample by adding observations from a wide range of years, restore the significance of the significance tests.^[If you are intressted, [Appendix 6][Appendix 6] shows how the models look like, when outliners are removed from the used dataset and the Jarque-Bera-Test show normal distribution] Cleaning up the aforementioned deficiencies subsequently allows the evaluation of relevance. Die Bereinigung der genannten Mägel erlaubt anschließend die Bewertung der Relevanz.^[cf. @Zuckarelli.2017 p. 232 et sqq.]

If subsequent studies with optimized regression analyses find similar results or, as in [Equation 3.1](#eq:equation2), a surprising positive correlation between cultural expenditure and the number of thefts, they can take a closer look not only at the relevance but also at the causality of the correlations. Furthermore,  studies by specified theft type or a differentiation of education and culture expenditures could offer more in-depth insights that draw stronger effects, if any. So, it remains to hope, they can develop potential findings to drive forward the reduction of theft in Germany.

***
# Appendix
## Appendix 1 {.unnumbered}
### Information about Runtime Environment {.unnumbered}
```{r Sessioninformation, echo=TRUE, warning=FALSE, paged.print=TRUE}
## Overall Session information
sessionInfo()

```
### List of Loaded Packages {.unnumbered}
```{r List of Loaded Packages, echo=TRUE, warning=FALSE, paged.print=TRUE}
## only Packages loaded as a list
sessionInfo_packages <- sessionInfo()["loadedOnly"]
toString(names(sessionInfo_packages$loadedOnly))

```

## Appendix 2 {.unnumbered .tabset .tabset-fade}

```{r renderRemaining Tabels for Cases, echo=TRUE, warning=FALSE}
table_thefts_allStates2015 <- addHtmlTableStyle(thefts_allStates_2015, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of Thefts in each Federal State and in total for Germany (2015)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2015")
table_thefts_allStates2017 <- addHtmlTableStyle(thefts_allStates_2017, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of Thefts in each Federal State and in total for Germany (2017)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2017")
table_thefts_allStates2016 <- addHtmlTableStyle(thefts_allStates_2016, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of Thefts in each Federal State and in total for Germany (2016)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2016")
table_thefts_allStates2018 <- addHtmlTableStyle(thefts_allStates_2018, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of Thefts in each Federal State and in total for Germany (2018)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2018")
table_thefts_allStates2019 <- addHtmlTableStyle(thefts_allStates_2019, pos.caption = "bottom", align="lllr",align.header = "lccr") %>% htmlTable(rnames=FALSE, caption="Number of Thefts in each Federal State and in total for Germany (2019)^[adapted from @Bundeskriminalamt.2023]", label="table_thefts_allStates2019")
```

### 2014 {-}
`r table_thefts_allStates2014`
### 2015 {-}
`r table_thefts_allStates2015`

### 2016 {-}
`r table_thefts_allStates2016`
### 2017 {-}
`r table_thefts_allStates2017`
### 2018 {-}
`r table_thefts_allStates2018`
### 2019 {-}
`r table_thefts_allStates2019`
### 2020 {-}
`r table_thefts_allStates2020`

## Appendix 3 {.unnumbered}
```{r unemployment rate appendix, echo=TRUE, message=FALSE, warning=FALSE}

# Shows the amount of unemployees in each federal state 
summary_Unemployment_full <- summary(jobless_people) %>% addHtmlTableStyle(pos.caption = "bottom", align="left",align.header = "left") %>% htmlTable(rnames=FALSE, caption="The structre presents the amount of unemployed people by colums of federal states^[adapted from @StatistischesBundesamtDeutschland.2023b]",  tfoot= "The relevant figures are splited around many colums and the variable of federal states is only presented by column headers. To be compatible with the other datasets is has to be pivotated to a longer dataset with one column per variable. This means one observation contains a variable/column for years, one for the fedaral state and one for the amount of unemployees in that year and federal state.", label="summary_Unemployment_full")

summary_Unemployment_full
```


## Appendix 4 {.unnumbered}
```{r increased summary view, echo=TRUE, message=FALSE, warning=FALSE}

## Creats a summary table for the new Dataset
summary_Cases_total<- summary(caseNumbers_allYears_transformed4Summary, maxsum = 30) %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(rnames=FALSE, caption="Summary of all yearly reports of Crimecases^[adapted from @Bundeskriminalamt.2023]", tfoot =  "Shows the Years as factors to visualise the amount of observerations per year. Furthermore there are many different Crimetypes listed, but necessary is only  **\"Diebstähle insgesamt und zwar\"** as mentiond in [par. 2.1](#Paragraph2_1). Additionally you can see under the FederalState 21 factors. For Baden-Württemberg and Thüringen you can see 2 possible expressions, because of the vowl *ü*. Furthermore you can see that there are Observations for **\"Bundesrepublik\"** and **\"Bund echte Zählung der Tatverdächtigen\"** which are unnecessary for this paper's regression." , label="summary_Cases_total")

summary_Cases_total
```

## Appendix 5 {.unnumbered}
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Significance-Test that takes also heteroscedasticity and autocorrelation into account 

## Modell 1
rM1_coeftest ## t-Test Result of Modell 1's Regressioncoefficients
rM1_F_Test ## F-Test Result of Modell 1
## Modell 2
rM2_coeftest ## t-Test Result of Modell 2's Regressioncoefficients
rM2_F_Test ## F-Test Result of Modell 2
rM2_F_Test2 ## F-Test Result of Modell 2
## Modell 3
rM3_coeftest ## t-Test Result of Modell 3's Regressioncoefficients
rM3_F_Test1 ## F-Test Result of Modell 3
rM3_F_Test2 ## F-Test Result of Modell 3

```

## Appendix 6 {.unnumbered}
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Dataset to buid regression without the Outliners Nordrhein-Westfalen, Berlin
# based on Discussion in Chapter 4 and Improvements described in Chapter 5 and only if you are curious for new results
mergedData4regression_optimised <- mergedData4regression[!(mergedData4regression$FederalState %in% c("Nordrhein-Westfalen", "Berlin")),] 
### Results can be seen in "./02_VerarbeiteteDaten/zusammenfassung_ohneAusreißer.html" - in short Jarque-Bera-test show normal-distributed residuals, significant results are truely significant

### Short variablenames are needed because stargazer can not work with longer Variable names
regMod_1_optimised <- lm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure, data=mergedData4regression_optimised[,-1])

regMod_2_optimised <- lm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure + Areasize + Year  -1, data=mergedData4regression_optimised[,-1])

regMod_3_optimised <- lm(TheftAmount ~ Population + GDP + AmountOfUnemployedPeople + TotalExpenditure4Education + CulturalTotalExpenditure + FederalState + Year -1, data=mergedData4regression_optimised[,-4])

Overview_RegModels <- read_html("./02_VerarbeiteteDaten/zusammenfassung_ohneAusreißer.html") %>% addHtmlTableStyle(pos.caption = "bottom", align="left", align.header = "left") %>% htmlTable(caption="Overview of all regression modells shows Model 3 as best result", tfoot =  "The Dataset used, was cleand from outlines, so that Jarque-Bera-Test could confirm a normal distribution of residuals. All regression models present significant estimators for  some of their variables, but the third model has a better adjusted R² and also includes control variables. Hence it is the most exact model for the data that was used. It leads to the conclusion that expenditures for education are negatively related to the number of thefts. Furthermore expenditures for culture are positively related to the number of thefts. The more federal states invest in  education, the fewer thefts appear." , label="Overview_RegModels")

jb_test_model2_optimised <- jarque.bera.test(regMod_2_optimised$residuals)
jb_test_model3_optimised <- jarque.bera.test(regMod_3_optimised$residuals)
Overview_RegModels
```

***
# References
***
